{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextRank Summary:\n",
      "Sri Vikrama Rajasinha of Kandy, the last ruling native Sri Lankan monarchDuring the Napoleonic Wars, fearing that French control of the Netherlands might deliver Sri Lanka to the French, the British Empire occupied the coastal areas of the island (which they called the colony of British Ceylon) with little difficulty in 1796.\n",
      "Buddhism is the largest and is considered as an \" Official religion\" of Sri Lanka under Chapter II, Article 9, \"The Republic of Sri Lanka shall give to Buddhism the foremost place and accordingly it shall be the duty of the State to protect and foster the Buddha Sasana\".\n",
      "[IMF] completed the first review of Sri Lanka's economic performance under the program supported by a three-year extended arrangement under the Extended Fund Facility (EFF) arrangement.^\"Sri Lanka : 2018 Article IV Consultation and the Fourth Review Under the Extended Arrangement Under the Extended Fund Facility-Press Release; Staff Report; and Statement by the Executive Director for Sri Lanka\".\n",
      "\n",
      "LexRank Summary:\n",
      "[397] and 2022.\n",
      "Sri Lanka.\n",
      "\"Sri Lanka\".\n",
      "\n",
      "LSA Summary:\n",
      "[232][233] Prior to 1987, all administrative tasks for the provinces were handled by a district-based civil service which had been in place since colonial times.\n",
      "ColomboKaduwela 1 ColomboWestern 561,31411 GalleSouthern 86,333\n",
      "2 KaduwelaWestern 252,04112 BatticaloaEastern 86,227\n",
      "3 MaharagamaWestern 196,42313 JaffnaNorthern 80,829\n",
      "4 KesbewaWestern 185,12214 MataraSouthern 74,193\n",
      "5 Dehiwala-Mount LaviniaWestern 184,46815 GampahaWestern 62,335\n",
      "6 MoratuwaWestern 168,28016 KatunayakeWestern 60,915\n",
      "7 NegomboWestern 142,44917 BoralesgamuwaWestern 60,110\n",
      "8 Sri Jayawardenepura KotteWestern 107,92518 KolonnawaWestern 60,044\n",
      "9 KalmunaiEastern 99,89319 AnuradhapuraNorth Central 50,595\n",
      "10 KandyCentral 98,82820 TrincomaleeEastern 48,351\n",
      "Retrieved 4 July 2022.^ Asian Religions in British Columbia, UBC Press 2011, p. 125.^ Lecture on Hindu sculpture and architecture of Sri Lanka Archived 12 October 2012 at the Wayback Machine Sunday Times – 29 September 2010^\"Lankan Muslims' historical links with India\".\n",
      "TextRank Summary:\n",
      "(<Sentence: Sri Vikrama Rajasinha of Kandy, the last ruling native Sri Lankan monarchDuring the Napoleonic Wars, fearing that French control of the Netherlands might deliver Sri Lanka to the French, the British Empire occupied the coastal areas of the island (which they called the colony of British Ceylon) with little difficulty in 1796.>, <Sentence: Buddhism is the largest and is considered as an \" Official religion\" of Sri Lanka under Chapter II, Article 9, \"The Republic of Sri Lanka shall give to Buddhism the foremost place and accordingly it shall be the duty of the State to protect and foster the Buddha Sasana\".>, <Sentence: [IMF] completed the first review of Sri Lanka's economic performance under the program supported by a three-year extended arrangement under the Extended Fund Facility (EFF) arrangement.^\"Sri Lanka : 2018 Article IV Consultation and the Fourth Review Under the Extended Arrangement Under the Extended Fund Facility-Press Release; Staff Report; and Statement by the Executive Director for Sri Lanka\".>)\n",
      "\n",
      "LexRank Summary:\n",
      "(<Sentence: [397] and 2022.>, <Sentence: Sri Lanka.>, <Sentence: \"Sri Lanka\".>)\n",
      "\n",
      "LSA Summary:\n",
      "(<Sentence: [232][233] Prior to 1987, all administrative tasks for the provinces were handled by a district-based civil service which had been in place since colonial times.>, <Sentence: ColomboKaduwela 1 ColomboWestern 561,31411 GalleSouthern 86,333\n",
      "2 KaduwelaWestern 252,04112 BatticaloaEastern 86,227\n",
      "3 MaharagamaWestern 196,42313 JaffnaNorthern 80,829\n",
      "4 KesbewaWestern 185,12214 MataraSouthern 74,193\n",
      "5 Dehiwala-Mount LaviniaWestern 184,46815 GampahaWestern 62,335\n",
      "6 MoratuwaWestern 168,28016 KatunayakeWestern 60,915\n",
      "7 NegomboWestern 142,44917 BoralesgamuwaWestern 60,110\n",
      "8 Sri Jayawardenepura KotteWestern 107,92518 KolonnawaWestern 60,044\n",
      "9 KalmunaiEastern 99,89319 AnuradhapuraNorth Central 50,595\n",
      "10 KandyCentral 98,82820 TrincomaleeEastern 48,351>, <Sentence: Retrieved 4 July 2022.^ Asian Religions in British Columbia, UBC Press 2011, p. 125.^ Lecture on Hindu sculpture and architecture of Sri Lanka Archived 12 October 2012 at the Wayback Machine Sunday Times – 29 September 2010^\"Lankan Muslims' historical links with India\".>)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pyproject\n",
    "# !pip install sumy\n",
    "# !pip install nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "# Download the data from the link\n",
    "url = 'https://en.wikipedia.org/wiki/Sri_Lanka'\n",
    "parser = HtmlParser.from_url(url, Tokenizer(\"english\"))\n",
    "\n",
    "# Summarize the text using TextRank\n",
    "text_rank_summarizer = TextRankSummarizer()\n",
    "text_rank_summary = text_rank_summarizer(parser.document, sentences_count=3)\n",
    "print(\"TextRank Summary:\")\n",
    "for sentence in text_rank_summary:\n",
    "  print(sentence)\n",
    "\n",
    "# Summarize the text using LexRank\n",
    "lex_rank_summarizer = LexRankSummarizer()\n",
    "lex_rank_summary = lex_rank_summarizer(parser.document, sentences_count=3)\n",
    "print(\"\\nLexRank Summary:\")\n",
    "for sentence in lex_rank_summary:\n",
    "  print(sentence)\n",
    "\n",
    "# Summarize the text using LSA\n",
    "lsa_summarizer = LsaSummarizer()\n",
    "lsa_summary = lsa_summarizer(parser.document, sentences_count=3)\n",
    "print(\"\\nLSA Summary:\")\n",
    "for sentence in lsa_summary:\n",
    "  print(sentence)\n",
    "\n",
    "# Print the summaries\n",
    "print(\"TextRank Summary:\")\n",
    "print(text_rank_summary)\n",
    "\n",
    "print(\"\\nLexRank Summary:\")\n",
    "print(lex_rank_summary)\n",
    "\n",
    "print(\"\\nLSA Summary:\")\n",
    "print(lsa_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstractive Summary:\n",
      " Sachin Tendulkar - Wikipedia Jump content Main menu Main menu move sidebar hide Navigation Main page . About WikipediaContact usDonate Contribute Contribute HelpLearn editCommunity portal .\n"
     ]
    }
   ],
   "source": [
    "# !pip install nltk beautifulsoup4 transformers\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import pipeline\n",
    "\n",
    "# Download the 'punkt' resource\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Download the data from the link\n",
    "url = 'https://en.wikipedia.org/wiki/Sachin_Tendulkar'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extract the plain text content\n",
    "text = soup.get_text()\n",
    "\n",
    "# Remove stop words (optional, might improve summarization)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [word for word in word_tokenize(text) if word.lower() not in stop_words]\n",
    "processed_text = \" \".join(words)  # Join the words back into a string\n",
    "\n",
    "# Summarize the text using transformers\n",
    "summarizer = pipeline(\"summarization\")\n",
    "abstract = summarizer(processed_text, max_length=100, min_length=30,truncation =True)\n",
    "\n",
    "# Print the summary\n",
    "print(\"Abstractive Summary:\")\n",
    "print(abstract[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The postman delivered the package to the wrong address.\n",
      "Bag of words: [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 3 1 0 0 0 0 0 0 0 1]\n",
      "Sentence: I wrapped a beautiful present for my friend's birthday.\n",
      "Bag of words: [0 0 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "Sentence: The delivery truck arrived late due to heavy traffic.\n",
      "Bag of words: [0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0]\n",
      "Sentence: We need to check the shipping address before sending the order.\n",
      "Bag of words: [1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 2 1 0 0 0 1 0 0 0 0]\n",
      "Sentence: Online shopping offers a wide variety of products with fast delivery.\n",
      "Bag of words: [0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a list of sentences\n",
    "sentences = [\n",
    "    \"The postman delivered the package to the wrong address.\",\n",
    "    \"I wrapped a beautiful present for my friend's birthday.\",\n",
    "    \"The delivery truck arrived late due to heavy traffic.\",\n",
    "    \"We need to check the shipping address before sending the order.\",\n",
    "    \"Online shopping offers a wide variety of products with fast delivery.\"\n",
    "]\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the sentences\n",
    "vectorizer.fit(sentences)\n",
    "\n",
    "# Create a bag of words for each sentence\n",
    "bag_of_words = vectorizer.transform(sentences)\n",
    "\n",
    "# Print the bag of words for each sentence\n",
    "for sentence, bag in zip(sentences, bag_of_words.toarray()):\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Bag of words: {bag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
