{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Declare the word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words1 = 'managing', 'manage', 'management', 'managerial', ' managed'\n",
    "words2 = 'worked', 'workeble', 'working', 'worked'\n",
    "words3 = 'big', 'biggest', 'bigger'\n",
    "words4 = 'go', 'gone', 'went', 'going'\n",
    "words5 = 'child', 'children'\n",
    "words6 = 'plays', 'playing', 'players'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manage'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize(words1[0], pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went --> go\n"
     ]
    }
   ],
   "source": [
    "print(words4[2], '-->', wnl.lemmatize(words4[2], pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigger --> big\n"
     ]
    }
   ],
   "source": [
    "print(words3[2], '-->', wnl.lemmatize(words3[1], pos='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "players --> player\n"
     ]
    }
   ],
   "source": [
    "print(words6[2], '-->', wnl.lemmatize(words6[2], pos='n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children --> child\n"
     ]
    }
   ],
   "source": [
    "print(words5[1], '-->', wnl.lemmatize(words5[1], pos='n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package spacy:\n",
      "\n",
      "NAME\n",
      "    spacy\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __main__\n",
      "    about\n",
      "    attrs\n",
      "    cli (package)\n",
      "    compat\n",
      "    displacy (package)\n",
      "    errors\n",
      "    git_info\n",
      "    glossary\n",
      "    kb (package)\n",
      "    lang (package)\n",
      "    language\n",
      "    lexeme\n",
      "    lookups\n",
      "    matcher (package)\n",
      "    ml (package)\n",
      "    morphology\n",
      "    parts_of_speech\n",
      "    pipe_analysis\n",
      "    pipeline (package)\n",
      "    schemas\n",
      "    scorer\n",
      "    strings\n",
      "    symbols\n",
      "    tests (package)\n",
      "    tokenizer\n",
      "    tokens (package)\n",
      "    training (package)\n",
      "    ty\n",
      "    util\n",
      "    vectors\n",
      "    vocab\n",
      "\n",
      "FUNCTIONS\n",
      "    blank(name: str, *, vocab: Union[spacy.vocab.Vocab, bool] = True, config: Union[Dict[str, Any], confection.Config] = {}, meta: Dict[str, Any] = {}) -> spacy.language.Language\n",
      "        Create a blank nlp object for a given language code.\n",
      "        \n",
      "        name (str): The language code, e.g. \"en\".\n",
      "        vocab (Vocab): A Vocab object. If True, a vocab is created.\n",
      "        config (Dict[str, Any] / Config): Optional config overrides.\n",
      "        meta (Dict[str, Any]): Overrides for nlp.meta.\n",
      "        RETURNS (Language): The nlp object.\n",
      "    \n",
      "    load(name: Union[str, pathlib.Path], *, vocab: Union[spacy.vocab.Vocab, bool] = True, disable: Union[str, Iterable[str]] = [], enable: Union[str, Iterable[str]] = [], exclude: Union[str, Iterable[str]] = [], config: Union[Dict[str, Any], confection.Config] = {}) -> spacy.language.Language\n",
      "        Load a spaCy model from an installed package or a local path.\n",
      "        \n",
      "        name (str): Package name or model path.\n",
      "        vocab (Vocab): A Vocab object. If True, a vocab is created.\n",
      "        disable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to disable. Disabled\n",
      "            pipes will be loaded but they won't be run unless you explicitly\n",
      "            enable them by calling nlp.enable_pipe.\n",
      "        enable (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to enable. All other\n",
      "            pipes will be disabled (but can be enabled later using nlp.enable_pipe).\n",
      "        exclude (Union[str, Iterable[str]]): Name(s) of pipeline component(s) to exclude. Excluded\n",
      "            components won't be loaded.\n",
      "        config (Dict[str, Any] / Config): Config overrides as nested dict or dict\n",
      "            keyed by section values in dot notation.\n",
      "        RETURNS (Language): The loaded nlp object.\n",
      "\n",
      "DATA\n",
      "    Dict = typing.Dict\n",
      "        A generic version of dict.\n",
      "    \n",
      "    Iterable = typing.Iterable\n",
      "        A generic version of collections.abc.Iterable.\n",
      "    \n",
      "    Union = typing.Union\n",
      "        Union type; Union[X, Y] means either X or Y.\n",
      "        \n",
      "        On Python 3.10 and higher, the | operator\n",
      "        can also be used to denote unions;\n",
      "        X | Y means the same thing to the type checker as Union[X, Y].\n",
      "        \n",
      "        To define a union, use e.g. Union[int, str]. Details:\n",
      "        - The arguments must be types and there must be at least one.\n",
      "        - None as an argument is a special case and is replaced by\n",
      "          type(None).\n",
      "        - Unions of unions are flattened, e.g.::\n",
      "        \n",
      "            assert Union[Union[int, str], float] == Union[int, str, float]\n",
      "        \n",
      "        - Unions of a single argument vanish, e.g.::\n",
      "        \n",
      "            assert Union[int] == int  # The constructor actually returns int\n",
      "        \n",
      "        - Redundant arguments are skipped, e.g.::\n",
      "        \n",
      "            assert Union[int, str, int] == Union[int, str]\n",
      "        \n",
      "        - When comparing unions, the argument order is ignored, e.g.::\n",
      "        \n",
      "            assert Union[int, str] == Union[str, int]\n",
      "        \n",
      "        - You cannot subclass or instantiate a union.\n",
      "        - You can use Optional[X] as a shorthand for Union[X, None].\n",
      "    \n",
      "    logger = <Logger spacy (WARNING)>\n",
      "\n",
      "VERSION\n",
      "    3.7.4\n",
      "\n",
      "FILE\n",
      "    c:\\users\\administrator.dai-pc2\\anaconda3\\lib\\site-packages\\spacy\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "help(spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
